name: Nightly Alibaba Cloud Linux2 SGX2

# This is a manual trigger and schedule to run everyday at 2AM CST.
on:
  workflow_dispatch:
  schedule:
    # Schedule to run everyday at 2AM CST
    - cron:  '0 18 * * *'

env:
  WORK_DIR: /root/pkgs
  HOME: /root
  OCCLUM_VERSION: 0.21.0
  kubernetes_version: 1.18.8
  nap_time: 60

jobs:
  k8s_aliyunlinux:
    runs-on: [self-hosted, SGX2, nightly, aliyunlinux]
    steps:
      - uses: actions/checkout@v1

      - uses: ./.github/actions/clean-nightly-env/aliyunlinux
        with:
          work-dir: ${WORK_DIR}

      # We usually update rune.spec to the latest version before release. Therefore we get the latest version according to rune.spec.
      - name: Get version
        run: echo "RUNE_VERSION=$(cat VERSION)" >> $GITHUB_ENV;
          echo "CPU_NUM=$(nproc --all)" >> $GITHUB_ENV

      - name: Install teesdk
        run: |
          mkdir -p /dev/sgx
          ln -s /dev/sgx_enclave /dev/sgx/enclave
          ln -s /dev/sgx_provision /dev/sgx/provision
          # Get regionid of the current node from ECS metadata API
          REGION=`curl --retry 10 -sSL http://100.100.100.200/2016-01-01/meta-data/region-id`
          sudo yum install -y yum-utils || true
          sudo yum-config-manager --add-repo \
              https://enclave-${REGION}.oss-${REGION}.aliyuncs.com/repo/alinux/enclave-expr.repo || return 1
          cat << EOF >/etc/yum.repos.d/inclavare-containers.repo
          [inclavare-containers]
          name=inclavare-containers
          enabled=1
          baseurl=https://mirrors.openanolis.org/inclavare-containers/alinux2-repo/
          gpgcheck=1
          repo_gpgcheck=1
          gpgkey=https://mirrors.openanolis.org/inclavare-containers/alinux2-repo/RPM-GPG-KEY-rpm-sign
          gpgcakey=https://mirrors.openanolis.org/inclavare-containers/alinux2-repo/RPM-GPG-KEY-rpm-sign-ca
          EOF
          sudo yum install -y gcc gcc-c++ \
            libsgx-ae-le libsgx-ae-pce libsgx-ae-qe3 libsgx-ae-qve \
            libsgx-aesm-ecdsa-plugin libsgx-aesm-launch-plugin libsgx-aesm-pce-plugin libsgx-aesm-quote-ex-plugin \
            libsgx-dcap-default-qpl libsgx-dcap-ql libsgx-dcap-quote-verify \
            libsgx-enclave-common libsgx-launch libsgx-pce-logic libsgx-qe3-logic libsgx-quote-ex \
            libsgx-ra-network libsgx-ra-uefi libsgx-uae-service libsgx-urts sgx-ra-service \
            sgx-aesm-service
          yum install -y teesdk || return 1
          cat << EOF > /etc/sgx_default_qcnl.conf
          # PCCS server address
          PCCS_URL=https://sgx-dcap-server.${REGION}.aliyuncs.com/sgx/certification/v3/
          # To accept insecure HTTPS cert, set this option to FALSE
          USE_SECURE_CERT=TRUE
          EOF
      # occlum-pal should be installed manually
      - name: Install Occlum stack
        run: |
          pushd ${WORK_DIR}
          if [ ! $(lsmod | grep enable_rdfsbase) ]; then
            yum install -y occlum-rdfsbase-dkms
          fi
          popd

      - name: Install rune and shim
        run: |
          yum install -y libseccomp-devel
          pushd $WORK_DIR
          cp -r $GITHUB_WORKSPACE inclavare-containers-$RUNE_VERSION
          tar zcf v$RUNE_VERSION.tar.gz inclavare-containers-$RUNE_VERSION
          cd inclavare-containers-$RUNE_VERSION
          echo "$RUNE_VERSION" > VERSION
          # build and install shim
          pushd ./shim
          GOOS=linux make
          chmod +x bin/containerd-shim-rune-v2
          /bin/cp -f bin/containerd-shim-rune-v2 /usr/local/bin
          mkdir -p /etc/inclavare-containers
          cat << EOF > /etc/inclavare-containers/config.toml
          log_level = "info" # "debug" "info" "warn" "error"
          sgx_tool_sign = "/opt/intel/sgxsdk/bin/x64/sgx_sign"
          [containerd]
              socket = "/run/containerd/containerd.sock"
          [enclave_runtime]
              # The signature_method represents the signature method for enclave.
              # It can be "server" or "client", the default value is "server"
              signature_method = "client"
          EOF
          openssl genrsa -out private_key.pem -3 3072
          openssl rsa -in private_key.pem -pubout -out public_key.pem
          go build -mod=vendor -o signatureserver cmd/signature-server/main.go || exit 1
          chmod +x signatureserver
          nohup ./signatureserver --public-key public_key.pem --private-key private_key.pem &
          sleep 2
          netstat -natp | grep 9080 || exit 1
          echo -e "[signature]\n    server_address = \"http://127.0.0.1:9080\"" >> /etc/inclavare-containers/config.toml
          systemctl restart aesmd
          popd
          # build and install rune
          pushd ./rune
          GOOS=linux make && make install
          popd
          popd

      - name: Configure containerd
        run: |
          cat <<- EOF >/etc/systemd/system/containerd.service
          [Unit]
          Description=containerd container runtime
          Documentation=https://containerd.io
          After=network.target

          [Service]
          ExecStartPre=/sbin/modprobe overlay
          ExecStart=/usr/local/bin/containerd
          Restart=always
          RestartSec=5
          Delegate=yes
          KillMode=process
          OOMScoreAdjust=-999
          LimitNOFILE=1048576
          LimitNPROC=infinity
          LimitCORE=infinity

          [Install]
          WantedBy=multi-user.target
          EOF

          mkdir -p /etc/containerd
          cat <<- EOF >/etc/containerd/config.toml
          [plugins]
            [plugins.cri]
              sandbox_image = "registry.cn-hangzhou.aliyuncs.com/acs/pause-amd64:3.1"
              [plugins.cri.containerd]
                default_runtime_name = "rune"
                snapshotter = "overlayfs"
                [plugins.cri.containerd.runtimes.rune]
                  runtime_type = "io.containerd.rune.v2"
          EOF

          sudo systemctl enable containerd.service
          sudo systemctl restart containerd.service

      - name: Install kubernetes
        run: |
          sudo modprobe br_netfilter
          cat <<- EOF | tee /etc/sysctl.d/k8s.conf
          net.bridge.bridge-nf-call-ip6tables = 1
          net.bridge.bridge-nf-call-iptables = 1
          net.ipv4.ip_forward = 1
          EOF

          sudo sysctl --system
          cat <<- EOF >/etc/yum.repos.d/kubernetes.repo
          [kubernetes]
          name=Kubernetes
          baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
          enabled=1
          gpgcheck=1
          repo_gpgcheck=1
          gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
          EOF

          sudo setenforce 0 || true
          sudo sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config
          sudo yum install -y --setopt=obsoletes=0 kubelet-$kubernetes_version kubeadm-$kubernetes_version kubectl-$kubernetes_version --disableexcludes=kubernetes

          cat << EOF >/usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf
          [Service]
          Environment="KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf"
          Environment="KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml"
          Environment="KUBELET_SYSTEM_PODS_ARGS=--max-pods 64 --pod-manifest-path=/etc/kubernetes/manifests"
          Environment="KUBELET_NETWORK_ARGS=--network-plugin=cni --cni-conf-dir=/etc/cni/net.d --cni-bin-dir=/opt/cni/bin"
          Environment="KUBELET_DNS_ARGS=--pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/acs/pause-amd64:3.0 --cluster-domain=cluster.local --cloud-provider=external"
          Environment="KUBELET_EXTRA_ARGS=--container-runtime=remote --container-runtime-endpoint=/run/containerd/containerd.sock"
          ExecStart=
          ExecStart=/usr/bin/kubelet \$KUBELET_KUBECONFIG_ARGS \$KUBELET_CONFIG_ARGS \$KUBELET_SYSTEM_PODS_ARGS \$KUBELET_NETWORK_ARGS \$KUBELET_DNS_ARGS \$KUBELET_EXTRA_ARGS
          EOF

          sudo systemctl enable kubelet.service

          if [ -f /etc/kubernetes/admin.conf ]; then
            echo y | kubeadm reset
          fi
          sudo systemctl enable kubelet.service
          kubeadm init --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers --kubernetes-version=v${kubernetes_version} \
            --pod-network-cidr="172.21.0.0/20" --service-cidr="172.20.0.0/20" --cri-socket=/run/containerd/containerd.sock

          mkdir -p $HOME/.kube
          sudo /bin/cp -f /etc/kubernetes/admin.conf $HOME/.kube/config
          sudo chown $(id -u):$(id -g) $HOME/.kube/config
          kubectl taint nodes $(hostname | tr 'A-Z' 'a-z') node.cloudprovider.kubernetes.io/uninitialized-
          kubectl taint nodes $(hostname | tr 'A-Z' 'a-z') node-role.kubernetes.io/master-
          if [ ! -f /tmp/kube-flannel.yml ]; then
            wget --retry-connrefused --waitretry=1 --read-timeout=20 --timeout=15 --tries=0\
                $WORK_DIR https://raw.githubusercontent.com/coreos/flannel/2140ac876ef134e0ed5af15c65e414cf26827915/Documentation/kube-flannel.yml\
                -O /tmp/kube-flannel.yml
          fi
          kubectl apply -f /tmp/kube-flannel.yml

      - name: Install runtimeclass
        run: |
          cat <<- EOF >$WORK_DIR/runtime.yaml
          apiVersion: node.k8s.io/v1beta1
          handler: rune
          kind: RuntimeClass
          metadata:
            name: rune
          EOF

          kubectl apply -f $WORK_DIR/runtime.yaml
          kubectl get runtimeclass

      - name: Check k8s
        timeout-minutes: 10
        run: |
          sleep $nap_time
          while true; do
            count=$(kubectl get pod -A | grep -c "1/1")
            if [ $count -eq 8 ]; then
              break
            fi
            sleep 5
          done

      - name: Run off-cloud signed pod
        run: |
          cp /etc/inclavare-containers/config.toml /etc/inclavare-containers/config.toml.bak
          sed -i 's/server/client/g' /etc/inclavare-containers/config.toml
          cat <<- EOF >$WORK_DIR/helloworld_offcloud.yaml
          apiVersion: v1
          kind: Pod
          metadata:
            labels:
              run: helloworld-offcloud
            name: helloworld-offcloud
            namespace: default
          spec:
            restartPolicy: Always
            containers:
              - command:
                - /bin/hello_world
                env:
                  - name: ENCLAVE_TYPE
                    value: intelSgx
                  - name: RUNE_CARRIER
                    value: occlum
                  - name: ENCLAVE_RUNTIME_LOGLEVEL
                    value: info
                  - name: ENCLAVE_RUNTIME_PATH
                    value: /opt/occlum/build/lib/libocclum-pal.so.${OCCLUM_VERSION}
                  - name: ENCLAVE_RUNTIME_ARGS
                    value: /run/rune/occlum_instance
                image: docker.io/inclavarecontainers/occlum-helloworld-client:${OCCLUM_VERSION}
                imagePullPolicy: IfNotPresent
                name: hello-world-client
            dnsPolicy: ClusterFirst
          EOF
          kubectl apply -f $WORK_DIR/helloworld_offcloud.yaml
          sleep $nap_time
          while true; do
            count=$(kubectl get pod helloworld-offcloud | grep "Running" | grep -c "1/1")
            if [ $count -eq 1 ]; then
              break
            fi
            sleep 5
          done
          timeout 3 kubectl logs -f helloworld-offcloud  | grep "Hello World" || true

      - uses: ./.github/actions/clean-nightly-env/aliyunlinux
        with:
          work-dir: ${WORK_DIR}
