The files in this directory are used to implement a skeleton enclave runtime in order to help to write your own enclave runtime.

Note that this code base is inspired by [v28 SGX in-tree driver](https://patchwork.kernel.org/patch/11418925/).

---

# Run skeleton with Docker
## Build liberpal-skeleton

`skeleton` depends on `protobuf-c` compiler. Please refer to [this step](https://github.com/protobuf-c/protobuf-c#building) to install it on your platform.

```shell
cd "${path_to_inclavare_containers}/rune/libenclave/internal/runtime/pal/skeleton"
make
cp liberpal-skeleton-v*.so /usr/lib
```
Debug enclave is generated by default. Please use `make PRODUCT_ENCLAVE=1` command to generate production enclave.

## Build skeleton container image
```shell
cd "${path_to_inclavare_containers}/rune/libenclave/internal/runtime/pal/skeleton"
cat >Dockerfile <<EOF
FROM centos:8.1.1911

RUN mkdir -p /run/rune
WORKDIR /run/rune

COPY encl.bin .
COPY encl.elf .
COPY encl.ss .
EOF
docker build . -t skeleton-enclave
```

## Build and install rune
Please refer to [this guide](https://github.com/alibaba/inclavare-containers#rune) to build `rune` from scratch.

---

# Run skeleton container image
## Configure OCI runtime
Add the `rune` OCI runtime configuration in dockerd config file, e.g, `/etc/docker/daemon.json`, in your system.

```json
{
	"runtimes": {
		"rune": {
			"path": "/usr/local/bin/rune",
			"runtimeArgs": []
		}
	}
}
```

then restart dockerd on your system.
> e.g. `sudo systemctl restart docker` for CentOS, or `sudo service docker restart` for Ubuntu

You can check whether `rune` is correctly picked as supported OCI runtime or not with
```shell
docker info | grep rune
Runtimes: rune runc
```

## Run skeleton container image with rune
Note that replace `${SKELETON_PAL_VERSION}` with the actual version number. Currently skeleton supports PAL API v1 and v2.

```shell
docker run -it --rm --runtime=rune \
  -e ENCLAVE_TYPE=intelSgx \
  -e ENCLAVE_RUNTIME_PATH=/usr/lib/liberpal-skeleton-v${SKELETON_PAL_VERSION}.so \
  -e ENCLAVE_RUNTIME_ARGS="debug" \
  skeleton-enclave
```

where:
- @ENCLAVE_TYPE: specify the type of enclave hardware to use, such as `intelSgx`.
- @ENCLAVE_PATH: specify the path to enclave runtime to launch.
- @ENCLAVE_ARGS: specify the specific arguments to enclave runtime, seperated by the comma.

In order to measure the overhead of enclave launch time, we add the `-s` option for `sgxsign` tool. For example, if `-s` option is `40960000`, skeleton will launch an enclave with `40960000` bytes of memory size.

---

# Run skeleton OCI bundle
Note: The following method to launch skeleton with `rune` is usually provided for developmemt purpose.

## Create skeleton bundle
In order to use `rune` you must have your container image in the format of an OCI bundle. If you have Docker installed you can use its `export` method to acquire a root filesystem from an existing skeleton Docker container image.

```shell
# create the top most bundle directory
cd "$HOME/rune_workdir"
mkdir rune-container
cd rune-container

# create the rootfs directory
mkdir rootfs

# export skeleton image via Docker into the rootfs directory
docker export $(docker create skeleton-enclave) | sudo tar -C rootfs -xvf -
```

After a root filesystem is populated you just generate a spec in the format of a config.json file inside your bundle. `rune` provides a spec command which is similar to `runc` to generate a template file that you are then able to edit.

```shell
rune spec
```

To find features and documentation for fields in the spec please refer to the [specs](https://github.com/opencontainers/runtime-spec) repository.

In order to run the skeleton bundle with `rune`, you need to configure enclave runtime as following:
```json
  "annotations": {
      "enclave.type": "intelSgx",
      "enclave.runtime.path": "/usr/lib/liberpal-skeleton-v${SKELETON_PAL_VERSION}.so",
      "enclave.runtime.args": "debug"
  }
```

where:
- @enclave.type: specify the type of enclave hardware to use, such as intelSgx.
- @enclave.runtime.path: specify the path to enclave runtime to launch.
- @enclave.runtime.args: specify the specific arguments to enclave runtime, seperated by the comma.

## Run skeleton
Assuming you have an OCI bundle from the previous step you can execute the container in this way.

```shell
cd "$HOME/rune_workdir/rune-container"
sudo rune run skeleton-enclave-container
```

## Run skeleton with rune attest command

`rune attest` command can get the local report or IAS report of enclave runtimes, you can refer to [this guide](https://github.com/alibaba/inclavare-containers/blob/master/rune/libenclave/internal/runtime/pal/skeleton/running_skeleton_with_rune_attest_command.md) to run skeleton with `rune attest` command.

---

# Enclave share mapping
Once an enclave is setup, it can be used by mapping enclave fd and enclave EPC address in other processes.
It saves enclave initialization time. Epm module is implemented including two parts: epm service used to store enclave in enclave pool and epm client used to consume enclave from epm service and produce enclave as well.

## Run epm service
You can run epm service following with epm [README](https://github.com/alibaba/inclavare-containers/blob/master/epm/README.md).

## Run epm client
Assuming you have an OCI bundle according to previous steps, please add config into config.json as following:
```json
"annotations": {
	"enclave.type": "intelSgx",
	"enclave.runtime.path": "/usr/lib/liberpal-skeleton-v3.so",
	"enclave.runtime.args": "epm"
}
```

```shell
cd "$HOME/rune_workdir/rune-container"
sudo rune run skeleton-enclave-container
```

---

# Enclave NULL dereference protection

The potential attacker may re-map zero page to induce the buggy enclave to
read the zero page fed with malicious data, or write the confidential data
to zero page.

In order to prevent from this attack, skeleton enclave runtime implements
enclave NULL dereference protection for OOT and in-tree drivers. However,
OOT and in-tree drivers have different designs and implementations. This
also affects the behavior of enclave NULL dereference protection.

In order to enable this protection for OOT driver, the restriction from
mmapping must be disabled:
```shell
sudo sysctl -w vm.mmap_min_addr=0
```
in-tree driver doesn't have to do it.

FIXME: Current implementation assuems the build, signing and running stages
are on the same platform.
